{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2wWLQlRq+Q3FQJ8dwB75H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rridss/NLP/blob/main/nlp3rd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##EXPERIMENT-3:\n",
        "##Processing Data and Language Processor"
      ],
      "metadata": {
        "id": "9k4onAw7vsHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aws7euRLvc4E",
        "outputId": "91fb9b07-0593-4af6-ae7d-e16e0ee9bcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "\n",
            "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\n",
            "It is a complex field that draws on many disciplines, including cognitive science, linguistics, computer science, and artificial intelligence.\n",
            "NLP technologies are used in a wide range of applications, such as machine translation, speech recognition, and text summarization.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install nltk\n",
        "\n",
        "# Import libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\n",
        "It is a complex field that draws on many disciplines, including cognitive science, linguistics, computer science, and artificial intelligence.\n",
        "NLP technologies are used in a wide range of applications, such as machine translation, speech recognition, and text summarization.\n",
        "\"\"\"\n",
        "\n",
        "# Print original text\n",
        "print(\"Original text:\")\n",
        "print(text)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokens = word_tokenize(text.lower())\n",
        "tokenized_text = \" \".join(tokens)\n",
        "print(\"Tokenized text:\")\n",
        "print(tokenized_text)\n",
        "print()\n",
        "\n",
        "# Punctuation removal\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stripped_tokens = [word.translate(table) for word in tokens]\n",
        "stripped_text = \" \".join(stripped_tokens)\n",
        "print(\"Text with punctuation removed:\")\n",
        "print(stripped_text)\n",
        "print()\n",
        "\n",
        "# Stop-word removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in stripped_tokens if word not in stop_words]\n",
        "filtered_text = \" \".join(filtered_tokens)\n",
        "print(\"Text with stopwords removed:\")\n",
        "print(filtered_text)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50wJp6i5vi9S",
        "outputId": "c7b97350-ee42-4e02-c173-270060bb0334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized text:\n",
            "natural language processing ( nlp ) is a subfield of linguistics , computer science , and artificial intelligence concerned with the interactions between computers and human language , in particular how to program computers to process and analyze large amounts of natural language data . it is a complex field that draws on many disciplines , including cognitive science , linguistics , computer science , and artificial intelligence . nlp technologies are used in a wide range of applications , such as machine translation , speech recognition , and text summarization .\n",
            "\n",
            "Text with punctuation removed:\n",
            "natural language processing  nlp  is a subfield of linguistics  computer science  and artificial intelligence concerned with the interactions between computers and human language  in particular how to program computers to process and analyze large amounts of natural language data  it is a complex field that draws on many disciplines  including cognitive science  linguistics  computer science  and artificial intelligence  nlp technologies are used in a wide range of applications  such as machine translation  speech recognition  and text summarization \n",
            "\n",
            "Text with stopwords removed:\n",
            "natural language processing  nlp  subfield linguistics  computer science  artificial intelligence concerned interactions computers human language  particular program computers process analyze large amounts natural language data  complex field draws many disciplines  including cognitive science  linguistics  computer science  artificial intelligence  nlp technologies used wide range applications  machine translation  speech recognition  text summarization \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "stemmed_text = \" \".join(stemmed_tokens)\n",
        "print(\"Stemmed text:\")\n",
        "print(stemmed_text)\n",
        "print()\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "lemmatized_text = \" \".join(lemmatized_tokens)\n",
        "print(\"Lemmatized text:\")\n",
        "print(lemmatized_text)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds29xIrOvjAK",
        "outputId": "305def1e-f6dc-47cf-bb22-e22fd92d7fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed text:\n",
            "natur languag process  nlp  subfield linguist  comput scienc  artifici intellig concern interact comput human languag  particular program comput process analyz larg amount natur languag data  complex field draw mani disciplin  includ cognit scienc  linguist  comput scienc  artifici intellig  nlp technolog use wide rang applic  machin translat  speech recognit  text summar \n",
            "\n",
            "Lemmatized text:\n",
            "natural language processing  nlp  subfield linguistics  computer science  artificial intelligence concerned interaction computer human language  particular program computer process analyze large amount natural language data  complex field draw many discipline  including cognitive science  linguistics  computer science  artificial intelligence  nlp technology used wide range application  machine translation  speech recognition  text summarization \n",
            "\n"
          ]
        }
      ]
    }
  ]
}